---
title: "Event 1"
date: "`r Sys.Date()`"
weight: 1
chapter: false
pre: " <b> 4.1. </b> "
---

# Summary Report: “AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS”

### Event Objectives

- Introduce core concepts of AI/ML and GenAI on AWS  
- Provide an overview of Amazon SageMaker and its end-to-end ML lifecycle  
- Demonstrate Generative AI workflows using Amazon Bedrock  
- Teach best practices in building, training, deploying, and scaling ML models on AWS  
- Showcase real demos to help participants gain practical understanding  

### Speakers

(The event was presented by AWS Vietnam engineers and specialists.)

- AWS Solutions Architect Team – AWS Vietnam  
- AI/ML Specialist Engineers – AWS SEA  
- Generative AI Experts – Amazon Bedrock Team

### Key Highlights

#### Understanding the AI/ML landscape

- Overview of AI/ML adoption trends in Vietnam and globally  
- Business use cases adopting predictive models and GenAI  
- The shift from traditional ML workflows to fully managed platforms (SageMaker)

#### Amazon SageMaker – End-to-end ML platform

- Data preparation, feature engineering, labeling  
- Model training, hyperparameter tuning, debugging  
- Deployment options: real-time endpoints, batch, serverless inference  
- Integrated MLOps capabilities  
- Live Demo: SageMaker Studio notebook, pipelines, and model deployment  

#### Generative AI with Amazon Bedrock

- Foundation Models: Claude, Llama, Titan — strengths and use cases  
- Prompt engineering:  
  - Few-shot  
  - Chain-of-thought  
  - Structured prompting  
- Retrieval-Augmented Generation (RAG):  
  - Knowledge base  
  - Embeddings  
  - Vector search  
- Bedrock Agents: building multi-step workflows  
- Safety and guardrails for GenAI apps  
- Live Demo: Build a GenAI chatbot using Amazon Bedrock  

#### Hands-on learning and discussions

- Real examples of GenAI in enterprise solutions  
- How AI transforms software engineering workflows  
- Best practices for scaling ML workloads with serverless and managed services  

### Key Takeaways

#### AI/ML and GenAI Knowledge

- Better understanding of the full ML lifecycle on AWS  
- Awareness of when to apply Foundation Models vs traditional ML  
- Improved prompt engineering skills  
- Clear knowledge of RAG architecture for enterprise search/chatbots  

#### Technical Architecture Skills

- Learned how SageMaker unifies development, training, deployment, and monitoring  
- Understood how to integrate Bedrock into backend applications  
- Learned differences between real-time inference, serverless inference, and batch transforms  
- Understood how to build safe, scalable GenAI applications with guardrails  

#### Modern AI Development Strategy

- Adopt MLOps to streamline ML development  
- Leverage Bedrock Agents to automate multi-step workflows  
- Use serverless and managed services to reduce operational overhead  
- Apply best practices for monitoring ML endpoints and model drift  

### Applying to Work

- Apply RAG architecture to enhance search/chatbot features in real applications  
- Use prompt engineering techniques to improve model response quality  
- Experiment with SageMaker Studio for future ML experiments  
- Integrate Bedrock into backend services for GenAI-powered features  
- Adopt scalable deployment patterns for ML-powered systems  

### Event Experience

Attending the “AWS Cloud Mastery Series #1 – AI/ML/GenAI on AWS” event was an eye-opening experience that expanded my understanding of modern AI/ML development. Key experiences included:

#### Learning from experts

- AWS engineers shared practical best practices and real business case studies  
- Learned how large organizations adopt ML pipelines and GenAI solutions  

#### Hands-on demonstrations

- Saw live demos of SageMaker training, deployment, and debugging  
- Watched Bedrock building a full GenAI chatbot in real-time  
- Understood how to integrate Foundation Models into applications via APIs  

#### Networking and discussions

- Interacted with AWS specialists and other developers  
- Exchanged ideas on RAG, Bedrock Agents, and ML architectures  
- Strengthened industry connections and developed soft skills  

#### Lessons learned

- Managed ML services significantly reduce development complexity  
- RAG is essential for enterprise-grade GenAI applications  
- Prompt engineering is a real skill that impacts model accuracy and safety  
- AI workloads must be monitored and secured like any production system  

### Event Photos
![Event 1 Photo](/images/e1.jpg)

> Overall, this event enriched my technical knowledge and gave me practical insights into AI/ML and GenAI development on AWS. It also motivated me to explore how these technologies can be applied in future projects and real-world applications.
